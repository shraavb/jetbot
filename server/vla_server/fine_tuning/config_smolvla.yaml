# SmolVLA Fine-tuning Configuration for JetBot
# Optimized for Jetson Nano and resource-constrained environments

model:
  # Base model (SmolVLM or SmolVLA)
  base_model_id: "HuggingFaceM4/SmolVLM-Instruct"

  # Action head configuration
  action_dim: 2  # (left_speed, right_speed)
  intermediate_size: 128  # Hidden layer size in action head
  dropout: 0.1

  # Backbone freezing (recommended for limited compute)
  freeze_backbone: true

training:
  # Epochs and batch size (keep batch_size small for Jetson)
  num_epochs: 20
  batch_size: 2

  # Learning rate (lower than OpenVLA since we're only training action head)
  learning_rate: 5.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1

  # Gradient settings
  max_grad_norm: 1.0

  # Mixed precision (recommended for GPU)
  fp16: true
  gradient_checkpointing: true

  # Checkpointing
  save_every_n_epochs: 5
  save_dir: "./models/smolvla_jetbot"

data:
  # Dataset paths
  train_dir: "./dataset_vla_synthetic_large"
  image_size: 224
  val_ratio: 0.1

# Jetson Nano specific optimizations
jetson:
  # Memory optimization
  low_cpu_mem_usage: true

  # Inference settings
  inference_batch_size: 1

  # TensorRT optimization (future)
  use_tensorrt: false

# Logging
logging:
  log_every_n_steps: 10
  verbose: true
